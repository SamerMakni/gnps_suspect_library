{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ftplib\n",
    "import requests\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot styling.\n",
    "plt.style.use(['seaborn-white', 'seaborn-paper'])\n",
    "plt.rc('font', family='serif')\n",
    "sns.set_palette(['#9e0059', '#6da7de', '#ee266d', '#dee000', '#eb861e'])\n",
    "sns.set_context('paper', font_scale=1.3)    # Single-column figure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Living data analysis performed on 2020-11-18.\n",
    "living_data_base_url = 'MSV000084314/updates/2020-11-18_mwang87_d115210a/other'\n",
    "ftp_prefix = f'ftp://massive.ucsd.edu/{living_data_base_url}'\n",
    "# Get the MassIVE IDs for all datasets included in the living data.\n",
    "ftp = ftplib.FTP('massive.ucsd.edu')\n",
    "ftp.login()\n",
    "ftp.cwd(f'{living_data_base_url}/CLUSTERINFO')\n",
    "msv_ids = [filename[:filename.find('_')] for filename in ftp.nlst()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect the number of MS2 spectra per dataset and file.\n",
    "# The number of MS2 spectra per file was determined using grep:\n",
    "# while read filename; do if [[ \"$filename\" == *.mz[Xx][Mm][Ll] ]]; then echo $filename:$(grep -c \"msLevel=\\\"2\\\"\" \"/data/massive/$filename\"); elif [[ \"$filename\" == *.mz[Mm][Ll] ]]; then echo $filename:$(grep -c \"name=\\\"ms level\\\" value=\\\"2\\\"\" /data/massive/\"$filename\"); fi done < filenames.txt > filenames_ms2.txt\n",
    "filenames = pd.DataFrame(\n",
    "    pd.read_csv('../../data/interim/filenames_ms2.txt', header=None,\n",
    "                names=['filename'], squeeze=True)\n",
    "    .str.rsplit(':', 1).to_list(), columns=['filename', 'spectra_ms2'])\n",
    "filenames['dataset'] = filenames['filename'].str.split('/', 1).str[0]\n",
    "filenames['spectra_ms2'] = filenames['spectra_ms2'].astype(int)\n",
    "# Add dataset titles.\n",
    "titles = requests.get('https://massive.ucsd.edu/ProteoSAFe/datasets_json.jsp'\n",
    "                      '#%7B%22query%22%3A%7B%7D%2C%22table_sort_history'\n",
    "                      '%22%3A%22createdMillis_dsc%22%7D').json()\n",
    "filenames = pd.merge(filenames,\n",
    "                     pd.DataFrame([(ds['dataset'].strip(), ds['title'])\n",
    "                                   for ds in titles['datasets']],\n",
    "                                  columns=['dataset', 'title']),\n",
    "                     'left', on='dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of datasets: {len(msv_ids)}')\n",
    "print(f'Number of MS/MS spectra: '\n",
    "      f'{filenames.loc[filenames[\"dataset\"].isin(msv_ids), \"spectra_ms2\"].sum():,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export GNPS library searching tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Construct a URL to import the datasets into library searching.\n",
    "datasets, n_datasets_split = filenames['dataset'].unique(), 200\n",
    "for start_i in range(0, len(datasets), n_datasets_split):\n",
    "    url = (f'https://gnps.ucsd.edu/ProteoSAFe/index.jsp?params={{'\n",
    "           f'\"workflow\":\"MOLECULAR-LIBRARYSEARCH-V2\",'\n",
    "           f'\"library_on_server\":\"d.speclibs;\",'\n",
    "           f'\"spec_on_server\":\"'\n",
    "           f'{\";\".join(\"d.\" + datasets[start_i:start_i + n_datasets_split] + \"/ccms_peak\")}\"}}')\n",
    "    print(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate suspect library identification performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_ids_std = ['308b3393', '18cf4e52', 'c0249eb6', 'debd3bbb',\n",
    "                '8cdb4d7d', 'a9e7e4b1', '334ed0d9', 'b55aef34']\n",
    "task_ids_sus = ['064be855', 'd243afb8', 'febab54d', 'eba0dfe6',\n",
    "                'e1d68975', '1df48f2d', 'b7f8c3d4', '50e3d8ae']\n",
    "filename = '../../data/processed/MOLECULAR-LIBRARYSEARCH-V2-{}-view_all_annotations_DB-main.tsv'\n",
    "filename_ids_std = (\n",
    "    pd.concat([pd.read_csv(filename.format(task_id),\n",
    "                           usecols=['full_CCMS_path'],\n",
    "                           sep='\\t', squeeze=True)\n",
    "               .value_counts() for task_id in task_ids_std])\n",
    "    .reset_index()\n",
    "    .rename(columns={'index': 'filename', 'full_CCMS_path': 'num_ids'}))\n",
    "filename_ids_sus = (\n",
    "    pd.concat([pd.read_csv(filename.format(task_id),\n",
    "                           usecols=['full_CCMS_path'],\n",
    "                           sep='\\t', squeeze=True)\n",
    "               .value_counts() for task_id in task_ids_sus])\n",
    "    .reset_index()\n",
    "    .rename(columns={'index': 'filename', 'full_CCMS_path': 'num_ids'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_ids = pd.merge(filename_ids_std, filename_ids_sus, 'outer',\n",
    "                        'filename', suffixes=['_std', '_sus']).fillna(0)\n",
    "filename_ids = pd.merge(filenames, filename_ids, 'left', 'filename')\n",
    "filename_ids = filename_ids.fillna(0)\n",
    "filename_ids['num_ids_std'] = filename_ids['num_ids_std'].astype(int)\n",
    "filename_ids['num_ids_sus'] = filename_ids['num_ids_sus'].astype(int)\n",
    "filename_ids = filename_ids[['dataset', 'filename', 'spectra_ms2',\n",
    "                             'num_ids_std', 'num_ids_sus']]\n",
    "\n",
    "dataset_ids = (filename_ids.groupby('dataset')\n",
    "               .agg({'spectra_ms2': 'sum',\n",
    "                     'num_ids_std': 'sum',\n",
    "                     'num_ids_sus': 'sum'})\n",
    "               .reset_index())\n",
    "dataset_ids['fold_change'] = (dataset_ids['num_ids_sus']\n",
    "                              / dataset_ids['num_ids_std'])\n",
    "mask = dataset_ids['dataset'].isin(msv_ids)\n",
    "dataset_ids.loc[mask, 'creation'] = 'included'\n",
    "dataset_ids.loc[~mask, 'creation'] = 'new'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of datasets: {len(set(list(dataset_ids[\"dataset\"].unique()) + msv_ids))}')\n",
    "print(f'Number of MS/MS spectra: {dataset_ids[\"spectra_ms2\"].sum():,}')\n",
    "print(f'Number of MS/MS spectra in creation data: '\n",
    "      f'{dataset_ids.loc[dataset_ids[\"creation\"] == \"included\", \"spectra_ms2\"].sum():,}')\n",
    "print(f'Number of MS/MS spectra in independent data: '\n",
    "      f'{dataset_ids.loc[dataset_ids[\"creation\"] == \"new\", \"spectra_ms2\"].sum():,}')\n",
    "\n",
    "id_rate_std = (dataset_ids[\"num_ids_std\"] / dataset_ids[\"spectra_ms2\"]).median()\n",
    "id_rate_sus = (dataset_ids[\"num_ids_sus\"] / dataset_ids[\"spectra_ms2\"]).median()\n",
    "print(f'Standard libraries annotations: '\n",
    "      f'{dataset_ids[\"num_ids_std\"].sum():,} ({id_rate_std:.2%})')\n",
    "print(f'Suspect library annotations: '\n",
    "      f'{dataset_ids[\"num_ids_sus\"].sum():,} ({id_rate_sus:.2%})')\n",
    "avg_fold_change = (dataset_ids.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "                   [\"fold_change\"].median())\n",
    "print(f'Suspect library annotation increase: {avg_fold_change:.2f}x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 7\n",
    "height = width / 1.618\n",
    "fig, ax = plt.subplots(figsize=(width, height))\n",
    "\n",
    "dataset_match_rate = dataset_ids.copy()\n",
    "dataset_match_rate['num_ids_std'] /= dataset_match_rate['spectra_ms2']\n",
    "dataset_match_rate['num_ids_sus'] /= dataset_match_rate['spectra_ms2']\n",
    "dataset_match_rate = dataset_match_rate.melt(\n",
    "    id_vars=['dataset', 'creation'],\n",
    "    value_vars=['num_ids_std', 'num_ids_sus'],\n",
    "    var_name='search_mode', value_name='num_ids')\n",
    "\n",
    "sns.boxplot(x='creation', y='num_ids', hue='search_mode',\n",
    "            data=dataset_match_rate, dodge=True, ax=ax, meanline=True,\n",
    "            showfliers=False, showmeans=True, meanprops={'color': '#2f2f2f'})\n",
    "for patch in ax.artists:\n",
    "    patch.set_facecolor((*patch.get_facecolor()[:3], .75))\n",
    "np.random.seed(1)    # Control jitter.\n",
    "sns.stripplot(x='creation', y='num_ids', hue='search_mode',\n",
    "              data=dataset_match_rate, dodge=True, edgecolor='gray',\n",
    "              linewidth=0.3, ax=ax, marker='.', clip_on=False, zorder=10)\n",
    "\n",
    "ax.set_ylim(0, 1)\n",
    "ax.yaxis.set_major_formatter(mticker.PercentFormatter(1, 0))\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles[:2],\n",
    "          ['Default libraries', 'Default libraries +\\nsuspect library'],\n",
    "          loc='upper right')\n",
    "\n",
    "n_included = len(msv_ids)\n",
    "n_not_included = dataset_match_rate.loc[\n",
    "    dataset_match_rate['creation'] == 'new', 'dataset'].nunique()\n",
    "ax.set_xticklabels(\n",
    "    [f'Included during creation\\n({n_included} datasets)',\n",
    "     f'Not included during creation\\n({n_not_included} datasets)'])\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel('Spectrum match rate')\n",
    "\n",
    "sns.despine(ax=ax)\n",
    "\n",
    "plt.savefig('evaluate_annotations.png', dpi=300, bbox_inches='tight',\n",
    "            facecolor='white')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 7\n",
    "height = width / 1.618\n",
    "fig, ax = plt.subplots(figsize=(width, height))\n",
    "\n",
    "dataset_ids_fold_change = dataset_ids[dataset_ids['num_ids_std'] > 0].copy()\n",
    "dataset_ids_fold_change['num_ids_fold'] = \\\n",
    "    dataset_ids_fold_change['num_ids_sus'] / dataset_ids_fold_change['num_ids_std']\n",
    "dataset_ids_fold_change = dataset_ids_fold_change.melt(\n",
    "    id_vars=['dataset', 'creation'], value_vars=['num_ids_fold'],\n",
    "    var_name='search_mode', value_name='num_ids')\n",
    "\n",
    "max_fold_change = 10\n",
    "dataset_ids_fold_change_plot = dataset_ids_fold_change.copy()\n",
    "dataset_ids_fold_change_plot.loc[\n",
    "    dataset_ids_fold_change['num_ids'] > max_fold_change,\n",
    "    'num_ids'] = max_fold_change + 0.1\n",
    "\n",
    "sns.histplot(x='num_ids', hue='creation', data=dataset_ids_fold_change_plot,\n",
    "             stat='count', binwidth=0.5, multiple='layer',\n",
    "             hue_order=['included', 'new'], legend=True, ax=ax)\n",
    "ax.axvline(dataset_ids_fold_change['num_ids'].median(), color='black',\n",
    "           ls='--')\n",
    "\n",
    "ax.set_yscale('log')\n",
    "\n",
    "ax.xaxis.set_major_locator(mticker.FixedLocator([2, 4, 6, 8, 10]))\n",
    "ax.set_xticklabels(['2', '4', '6', '8', '≥10'])\n",
    "\n",
    "ax.set_xlabel('Spectrum match rate fold change')\n",
    "ax.set_ylabel('Number of datasets')\n",
    "\n",
    "ax.legend(ax.get_legend().legendHandles,\n",
    "          ['Datasets included during creation',\n",
    "           'Datasets not included during creation'],\n",
    "          loc='upper right')\n",
    "\n",
    "sns.despine(ax=ax)\n",
    "\n",
    "plt.savefig('evaluate_annotations_fold_change.png', dpi=300,\n",
    "            bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Median/mean/maximum spectrum match rate fold change: '\n",
    "      f'{dataset_ids_fold_change[\"num_ids\"].median():.2f} / '\n",
    "      f'{dataset_ids_fold_change[\"num_ids\"].mean():.2f} / '\n",
    "      f'{dataset_ids_fold_change[\"num_ids\"].max():.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redu = (pd.read_csv('../../data/interim/redu_all_sampleinformation.tsv',\n",
    "                    sep='\\t', usecols=['filename', 'SampleType'])\n",
    "        .rename(columns={'SampleType': 'sample_type'}))\n",
    "redu['filename'] = redu['filename'].str[2:]\n",
    "filename_ids_redu = pd.merge(filename_ids, redu, on='filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 7\n",
    "height = width / 1.618\n",
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(width, height * 2))\n",
    "\n",
    "sample_types = ('animal', 'food', 'culture_bacterial', 'plant',\n",
    "                'environmental', 'culture_fungal')\n",
    "\n",
    "for ax, (sample_type, ids_sample_type) in zip(\n",
    "        axes.flat,\n",
    "        (filename_ids_redu[filename_ids_redu['sample_type'].isin(sample_types)]\n",
    "         .groupby('sample_type'))):\n",
    "    ids_sample_type = (ids_sample_type.groupby('dataset').agg(\n",
    "        {'spectra_ms2': 'sum', 'num_ids_std': 'sum', 'num_ids_sus': 'sum'}))\n",
    "    ids_sample_type['num_ids_std'] /= ids_sample_type['spectra_ms2']\n",
    "    ids_sample_type['num_ids_sus'] /= ids_sample_type['spectra_ms2']\n",
    "    ax.scatter(np.repeat(0, len(ids_sample_type)),\n",
    "               ids_sample_type['num_ids_std'],\n",
    "               c='#6da7de', label='std')\n",
    "    ax.scatter(np.repeat(1, len(ids_sample_type)),\n",
    "               ids_sample_type['num_ids_sus'],\n",
    "               c='#6da7de', label='sus')\n",
    "    for std, sus in zip(ids_sample_type['num_ids_std'],\n",
    "                        ids_sample_type['num_ids_sus']):\n",
    "        ax.plot([0, 1], [std, sus], c='#6da7de', alpha=0.1)\n",
    "    \n",
    "    ax.set_xlim(-0.5, 1.5)\n",
    "    ax.set_ylim(0, ax.get_ylim()[1])\n",
    "    \n",
    "    ax.yaxis.set_major_formatter(mticker.PercentFormatter(1, 0))\n",
    "    ax.yaxis.set_major_locator(mticker.MaxNLocator('auto', steps=[1, 2, 5, 10]))\n",
    "    \n",
    "    ax.set_xticks([0, 1])\n",
    "    ax.set_xticklabels(['Default libraries',\n",
    "                        'Default libraries\\n+\\nsuspect library'], rotation=90)\n",
    "    ax.set_ylabel('Spectrum match rate')\n",
    "    \n",
    "    ax.set_title(f'{sample_type.replace(\"_\", \" \")}\\n'\n",
    "                 f'({ids_sample_type[\"spectra_ms2\"].sum():,} spectra)')\n",
    "\n",
    "    sns.despine(ax=ax)\n",
    "    \n",
    "for ax in axes[0, :]:\n",
    "    ax.set_xticklabels([])\n",
    "for ax in axes[:, 1:].flat:\n",
    "    ax.set_ylabel('')\n",
    "    \n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('evaluate_annotations_sample_type.png', dpi=300,\n",
    "            bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
