{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation of candidate suspect list\n",
    "\n",
    "Julia M. Gauglitz\n",
    "\n",
    "Date: 4/20/2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm.notebook as tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function 'id_clean' used for editing IDs table\n",
    "\n",
    "Define library ID inclusion criteria: \n",
    "1. MZErrorPPM <= 20\n",
    "2. SharedPeaks >= 6\n",
    "3. Include only entries with an INCHI; INCHI is not equal to 'N/A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_ids(ids: pd.DataFrame, max_ppm: float = 20,\n",
    "               min_shared_peaks: int = 6) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Filter high-quality identifications according to the given maximum ppm\n",
    "    deviation and minimum number of shared peaks. Identifications without an\n",
    "    InChI will be omitted as well.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    ids : pd.DataFrame\n",
    "        The tabular identifications retrieved from GNPS.\n",
    "    max_ppm : float\n",
    "        The maximum ppm deviation.\n",
    "    min_shared_peaks : int\n",
    "        The minimum number of shared peaks.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The identifications retained after filtering.\n",
    "    \"\"\"\n",
    "    return (ids[(ids['MZErrorPPM'].abs() <= max_ppm) &\n",
    "                (ids['SharedPeaks'] >= min_shared_peaks)]\n",
    "            .dropna(subset=['INCHI']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Editing pairs table\n",
    "\n",
    "Define criteria for pairs dictionary to include as candidate analog annotations (didn't filter any in example MSV000078547)\n",
    "1. Cosine >= 0.8\n",
    "2. Define DeltaMZ to be taken into account (i.e. 14, 16, 28); m/z delta +/- 20ppm difference at 1500 m/z ; assign putative_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elements = {'CH2': 14.016, 'O': 15.9965, 'C2H4': 28.032}\n",
    "\n",
    "def pairs_explain_mass_diff(pairs: pd.DataFrame, delta_mass: float = 0.05,\n",
    "                            min_cosine: float = 0.8) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Match mass differences between cluster pairs to known elements.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    pairs : pd.DataFrame\n",
    "        The tabular pairs retrieved from GNPS.\n",
    "    delta_mass : float\n",
    "        The delta mass (Da) used to matched pairs mass differences to known\n",
    "        elements.\n",
    "    min_cosine : float\n",
    "        The minimum cosine used to retain high-quality pairs.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The pairs to which an element could be matched based on their mass\n",
    "        differences.\n",
    "    \"\"\"\n",
    "    # Omit pairs with a low cosine score.\n",
    "    pairs = pairs[pairs['Cosine'] >= min_cosine]\n",
    "    # Match mass differences to putative identifications.\n",
    "    pairs['PutativeID'] = np.nan\n",
    "    for element, mass_shift in elements.items():\n",
    "        matched_mass_shift = pairs['DeltaMZ'].abs().between(\n",
    "            mass_shift - delta_mass, mass_shift + delta_mass)\n",
    "        pairs.loc[matched_mass_shift, 'PutativeID'] = element\n",
    "    return pairs.dropna(subset=['PutativeID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for editing summary table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_max_intensity_scan_per_cluster(summary: pd.DataFrame) \\\n",
    "        -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For each cluster select as representative the scan with the highest\n",
    "    precursor intensity.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    summary : pd.DataFrame\n",
    "        The tabular summary retrieved from GNPS.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The summary with only the scans with the highest precursor intensity\n",
    "        for each cluster.\n",
    "    \"\"\"\n",
    "    return (\n",
    "        summary.reindex(summary.groupby('cluster index')\n",
    "                        ['sum(precursor intensity)'].idxmax())\n",
    "        .reset_index(drop=True)\n",
    "        [['cluster index', 'ScanNumber', 'Original_Path']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ID clustered spectra to add to library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ID clustered spectra to add to library\n",
    "\n",
    "Function: Find the pairs, based on filtered input files. Create a column that contains the opposite clusterid, which is the scan number needed to add a new suspect annotation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_suspect_pairs(ids: pd.DataFrame, pairs: pd.DataFrame,\n",
    "                          summary: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Combine suspects pairs with identification and library information.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    ids : pd.DataFrame\n",
    "        The filtered identifications.\n",
    "    pairs : pd.DataFrame\n",
    "        The pairs with mass difference explanations.\n",
    "    summary : pd.DataFrame\n",
    "        The summary information for the clusters.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        A DataFrame with information about both spectra forming the suspect\n",
    "        identification.\n",
    "    \"\"\"\n",
    "    suspects = (pd.concat(\n",
    "        [(pd.merge(pairs, ids, left_on='CLUSTERID1', right_on='#Scan#')\n",
    "          .drop(columns=['CLUSTERID1'])\n",
    "          .rename(columns={'CLUSTERID2': 'SuspectIndex'})),\n",
    "         (pd.merge(pairs, ids, left_on='CLUSTERID2', right_on='#Scan#')\n",
    "          .drop(columns=['CLUSTERID2'])\n",
    "          .rename(columns={'CLUSTERID1': 'SuspectIndex'}))],\n",
    "        ignore_index=True, sort=False).dropna(axis=1))\n",
    "    sign = (suspects['DeltaMZ'] > 0).map({False: '-', True: '+'})\n",
    "    suspects['Suspect'] = ('Suspect related to ' +\n",
    "                           suspects['Compound_Name'] + ' ' + sign + ' ' +\n",
    "                           suspects['PutativeID'])\n",
    "    # TODO: Properly handle these warnings.\n",
    "    if not suspects['Suspect'].is_unique:\n",
    "        print('Multiple suspect matches per LibraryID found')\n",
    "    if not suspects['SuspectIndex'].is_unique:\n",
    "        print('Multiple analog matches per suspect scan found')\n",
    "    \n",
    "    suspects = pd.merge(suspects, summary, left_on='SuspectIndex',\n",
    "                        right_on='cluster index')\n",
    "    suspects = pd.merge(suspects, summary, left_on='#Scan#',\n",
    "                        right_on='cluster index', suffixes=('', '_library'))\n",
    "    return suspects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate suspect library using functions defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suspects_all = []\n",
    "ftp_prefix = 'ftp://massive.ucsd.edu/MSV000084314/other'\n",
    "for msv_id in tqdm.tqdm(pd.read_csv('filenames3.csv').squeeze()[:5],\n",
    "                        desc='Datasets processed', unit='dataset'):\n",
    "    ids = pd.read_csv(\n",
    "        f'{ftp_prefix}/IDENTIFICATIONS/{msv_id}_identifications.tsv',\n",
    "        sep='\\t', usecols=['Compound_Name', 'Adduct', 'Precursor_MZ',\n",
    "                           'INCHI', 'SpectrumID', 'LibraryQualityString',\n",
    "                           '#Scan#', 'MZErrorPPM', 'SharedPeaks'])\n",
    "    pairs = pd.read_csv(\n",
    "        f'{ftp_prefix}/PAIRS/{msv_id}_pairs.tsv', sep='\\t',\n",
    "        usecols=['CLUSTERID1', 'CLUSTERID2', 'DeltaMZ', 'Cosine'])\n",
    "    summary = pd.read_csv(\n",
    "        f'{ftp_prefix}/CLUSTERSUMMARY/{msv_id}_summary.tsv', sep='\\t',\n",
    "        usecols=['cluster index', 'sum(precursor intensity)', 'ScanNumber',\n",
    "                 'Original_Path'])\n",
    "    \n",
    "    ids = filter_ids(ids)\n",
    "    pairs = pairs_explain_mass_diff(pairs)\n",
    "    summary = summary_max_intensity_scan_per_cluster(summary)\n",
    "    suspects = combine_suspect_pairs(ids, pairs, summary)\n",
    "    if len(suspects) > 0:\n",
    "        suspects_all.append(suspects)\n",
    "suspects_all = pd.concat(suspects_all, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suspects_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create output for suspect library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output: spectral library batch file\n",
    "\n",
    "#batch upload for adding spectral library\n",
    "(1 spectrum per analog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suspects_all.to_csv('suspect_library_5MSV_20200423.txt', sep='\\t',\n",
    "#                     index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To investigate: \n",
    "\n",
    "Check if molecular formula varies by the same atoms as proposed based on the nominal mass difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add in conditionals of what to change / or data to summarize with regards to overlaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns to get from elsewhere: 'PI', 'Data Collector', 'Instrument', 'Ion_Source', 'IonMode' - based on the Unique Filepath"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
