{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation of candidate suspect list\n",
    "\n",
    "Julia M. Gauglitz\n",
    "\n",
    "Date: 4/20/2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function 'id_clean' used for editing IDs table\n",
    "\n",
    "Define library ID inclusion criteria: \n",
    "1. MZErrorPPM <= 20\n",
    "2. SharedPeaks >= 6\n",
    "3. Include only entries with an INCHI; INCHI is not equal to 'N/A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example call: id_clean(IDs)\n",
    "def id_clean(IDs):\n",
    "    INCHI = IDs['INCHI']\n",
    "    INCHI_TF = INCHI.notna()\n",
    "    IDs['INCHI_TF'] = INCHI_TF\n",
    "    IDs_subset = IDs.loc[(IDs['MZErrorPPM'] <= 20.0) & (IDs['SharedPeaks'] >= 6) & (IDs['INCHI_TF'] == True)]\n",
    "    return IDs_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Editing pairs table\n",
    "\n",
    "Define criteria for pairs dictionary to include as candidate analog annotations (didn't filter any in example MSV000078547)\n",
    "1. Cosine >= 0.8\n",
    "2. Define DeltaMZ to be taken into account (i.e. 14, 16, 28); m/z delta +/- 20ppm difference at 1500 m/z ; assign putative_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example call: pairs_clean(pairs)\n",
    "def pairs_clean(pairs):\n",
    "    #create new column for abs of deltamz\n",
    "    pairs['abs_DeltaMZ'] = pairs['DeltaMZ'].abs()\n",
    "    #add putative ID of mass difference into column 'putative_ID'\n",
    "    pairs.loc[(pairs['abs_DeltaMZ'] > 13.956) & (pairs['abs_DeltaMZ'] < 14.076), 'putative_ID'] = 'CH2'\n",
    "    pairs.loc[(pairs['abs_DeltaMZ'] > 15.936) & (pairs['abs_DeltaMZ'] < 16.056), 'putative_ID'] = 'O'\n",
    "    pairs.loc[(pairs['abs_DeltaMZ'] > 27.972) & (pairs['abs_DeltaMZ'] < 28.092), 'putative_ID'] = 'C2H4'\n",
    "    #add in additional - if name not known, then make equal to the mean mass\n",
    "    #drop rows that don't have an entry in putative_ID\n",
    "    pairs['putative_ID'].replace('', np.nan, inplace=True)\n",
    "    pairs_subset = pairs.dropna(subset=['putative_ID'])\n",
    "    #subset pairs df to omit low value cosine scores\n",
    "    pairs_subset = pairs_subset.loc[(pairs_subset['Cosine'] >= 0.8)]\n",
    "    return pairs_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for editing summary table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset summary to only include the spectrum with the max precursor intensity. \n",
    "#group by cluster index, then get the index of the max column value and then select that row from the dataframe.\n",
    "#example call: summary_clean(summary)\n",
    "def summary_clean(summary):\n",
    "    summary_max_filter = summary.loc[summary.groupby('cluster index')['sum(precursor intensity)'].idxmax()]\n",
    "    #copying table\n",
    "    summary_max_lib = summary_max_filter.copy()\n",
    "    #adding in columns to merge\n",
    "    summary_max_lib['cluster_index_lib'] = summary_max_lib['cluster index']\n",
    "    summary_max_lib['ScanNumber_lib'] = summary_max_lib['ScanNumber']\n",
    "    summary_max_lib['Original_Path_lib'] = summary_max_lib['Original_Path']\n",
    "    summary_max_lib = summary_max_lib[['cluster_index_lib','ScanNumber_lib','Original_Path_lib']].copy()\n",
    "    return summary_max_filter, summary_max_lib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ID clustered spectra to add to library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ID clustered spectra to add to library\n",
    "\n",
    "Function: Find the pairs, based on filtered input files. Create a column that contains the opposite clusterid, which is the scan number needed to add a new suspect annotation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example call: concat_pairs(IDs_subset,pairs_subset,summary_max_filter) ; as long as the inputs have been defined previously\n",
    "def concat_pairs(IDs_subset,pairs_subset,summary_max_filter,summary_max_lib):\n",
    "    clusterid1_pairs = pd.merge(pairs_subset, IDs_subset, left_on='CLUSTERID1', right_on='#Scan#')\n",
    "    clusterid1_pairs['suspect_index'] = clusterid1_pairs['CLUSTERID2']\n",
    "    clusterid1_pairs['sign'] = '+'\n",
    "    clusterid2_pairs = pd.merge(pairs_subset, IDs_subset, left_on='CLUSTERID2', right_on='#Scan#')\n",
    "    clusterid2_pairs['suspect_index'] = clusterid2_pairs['CLUSTERID1']\n",
    "    clusterid2_pairs['sign'] = '-'\n",
    "    #concatenate the two dataframes\n",
    "    suspect_pairs = pd.concat([clusterid1_pairs, clusterid2_pairs])\n",
    "    suspect_pairs.reset_index(drop=True, inplace=True)\n",
    "    #define suspect compound name\n",
    "    suspect_pairs[\"Suspect Name\"] = \"Suspect related to \" + suspect_pairs[\"Compound_Name\"] + \" \" + suspect_pairs[\"sign\"] + suspect_pairs[\"putative_ID\"]\n",
    "    \n",
    "    #if this is a function, should spit out a warning\n",
    "    boolean = not suspect_pairs['Suspect Name'].is_unique\n",
    "    boolean\n",
    "\n",
    "    if boolean == True:\n",
    "        print('There is more than one suspect match per LibraryID')\n",
    "    \n",
    "    #if this is a function, should spit out a warning\n",
    "    boolean = not suspect_pairs['suspect_index'].is_unique\n",
    "    boolean\n",
    "\n",
    "    if boolean == True:\n",
    "        print('There is more than one analog match per suspect scan')\n",
    "    \n",
    "    #the first columns refer to the annotation that was used to propagate to the suspect\n",
    "    #then come the suspect name, index\n",
    "    new_suspect_pairs = suspect_pairs[['#Scan#', 'abs_DeltaMZ', 'Compound_Name', 'Precursor_MZ', 'Adduct', 'LibraryQualityString', 'SpectrumID', 'Suspect Name', 'suspect_index']].copy()\n",
    "    \n",
    "    #to add: add in the filepath and scan number for the identified compound - \n",
    "    #will be the feature with highest precursor intensity that matches to #Scan#\n",
    "    suspect_library = pd.merge(new_suspect_pairs, summary_max_filter, left_on='suspect_index', right_on='cluster index')\n",
    "    suspect_library2 = pd.merge(suspect_library, summary_max_lib, left_on='#Scan#', right_on='cluster_index_lib')\n",
    "    \n",
    "    return suspect_library2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate suspect library using functions defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract list of MSV IDs from CLUSTERSUMMARY folder\n",
    "MSV923_apr232020 = pd.read_csv('filenames3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jgauglitz/miniconda3/envs/qiime2-2019.7/lib/python3.6/site-packages/ipykernel_launcher.py:5: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is more than one suspect match per LibraryID\n",
      "There is more than one analog match per suspect scan\n",
      "There is more than one suspect match per LibraryID\n",
      "There is more than one analog match per suspect scan\n",
      "There is more than one analog match per suspect scan\n",
      "There is more than one suspect match per LibraryID\n",
      "There is more than one suspect match per LibraryID\n",
      "There is more than one suspect match per LibraryID\n",
      "There is more than one analog match per suspect scan\n",
      "There is more than one suspect match per LibraryID\n",
      "There is more than one analog match per suspect scan\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot set a frame with no defined index and a scalar",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-a43f608debb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mIDs_subset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mid_clean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIDs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mpairs_subset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpairs_clean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0msummary_max_filter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary_max_lib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummary_clean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0msuspect_library2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcat_pairs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIDs_subset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpairs_subset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msummary_max_filter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msummary_max_lib\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-8af15992a5e4>\u001b[0m in \u001b[0;36mpairs_clean\u001b[0;34m(pairs)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mpairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'abs_DeltaMZ'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'DeltaMZ'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#add putative ID of mass difference into column 'putative_ID'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mpairs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'abs_DeltaMZ'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m13.956\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'abs_DeltaMZ'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m14.076\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'putative_ID'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'CH2'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mpairs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'abs_DeltaMZ'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m15.936\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'abs_DeltaMZ'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m16.056\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'putative_ID'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'O'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mpairs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'abs_DeltaMZ'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m27.972\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'abs_DeltaMZ'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m28.092\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'putative_ID'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'C2H4'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/qiime2-2019.7/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_setitem_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/qiime2-2019.7/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[0;34m(self, indexer, value)\u001b[0m\n\u001b[1;32m    354\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlen_non_info_axes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_list_like_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m                                 raise ValueError(\"cannot set a frame with no \"\n\u001b[0m\u001b[1;32m    357\u001b[0m                                                  \"defined index and a scalar\")\n\u001b[1;32m    358\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot set a frame with no defined index and a scalar"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "msv_ids = MSV923_apr232020['filenames3.txt'].tolist()\n",
    "#msv_ids = ['MSV000078547', 'MSV000078548', 'MSV000078551', 'MSV000078552', 'MSV000078556']\n",
    "for msv_id in msv_ids:\n",
    "    IDs = pd.read_csv(f'ftp://massive.ucsd.edu/MSV000084314/other/IDENTIFICATIONS/{msv_id}_identifications.tsv', sep='\\t')\n",
    "    pairs = pd.read_csv(f'ftp://massive.ucsd.edu/MSV000084314/other/PAIRS/{msv_id}_pairs.tsv', sep='\\t')\n",
    "    summary = pd.read_csv(f'ftp://massive.ucsd.edu/MSV000084314/other/CLUSTERSUMMARY/{msv_id}_summary.tsv', sep='\\t')\n",
    "    \n",
    "    IDs_subset = id_clean(IDs)\n",
    "    pairs_subset = pairs_clean(pairs)\n",
    "    summary_max_filter, summary_max_lib = summary_clean(summary)\n",
    "    suspect_library2 = concat_pairs(IDs_subset,pairs_subset,summary_max_filter,summary_max_lib)\n",
    "    results.append(suspect_library2)\n",
    "    \n",
    "final_result = pd.concat(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result.reset_index(drop=True, inplace=True)\n",
    "final_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create output for suspect library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output: spectral library batch file\n",
    "\n",
    "#batch upload for adding spectral library\n",
    "(1 spectrum per analog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_result.to_csv('suspect_library_5MSV_20200423.txt', sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To investigate: \n",
    "\n",
    "Check if molecular formula varies by the same atoms as proposed based on the nominal mass difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add in conditionals of what to change / or data to summarize with regards to overlaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns to get from elsewhere: 'PI', 'Data Collector', 'Instrument', 'Ion_Source', 'IonMode' - based on the Unique Filepath"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
